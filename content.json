[{"title":"Storm学习02：八种grouping分组策略","date":"2019-06-11T08:24:43.140Z","path":"20190611/storm-learning-02-eight-grouping-strategies.html","text":"简述为拓扑中的每个 Bolt 的确定输入数据流是定义一个拓扑的重要环节。数据流分组定义了在 Bolt 的不同任务（tasks）中划分数据流的方式。 在 Storm 中有八种内置的数据流分组方式，而且还可以通过 CustomStreamGrouping接口实现自定义的数据流分组模型。（所以总共可以算是九种分组方式） 具体分组这八种分组分时分别为： Shuffle grouping：随机分组。这种方式下元组会被尽可能随机地分配到Bolt的不同任务（tasks）中，使得每个任务所处理元组数量能够保持基本一致，以确保集群的负载均衡。 Fields grouping：按字段分组。这种方式下数据流根据定义的Field来进行分组。比如，如果某个数据流是基于一个名为“user-id”的字段进行分组的，那么所有包含相同的“user-id”的tuple都会被分配到同一个任务中，这样就可以确保消息处理的一致性。 Partial Key grouping：部分关键字分组。这种方式与Fields grouping很相似，根据定义的域来对数据流进行分组，不同的是，这种方式会考虑下游Bolt数据处理的均衡性问题，在输入数据源关键字不平衡时会有更好的性能。 All grouping：完全分组。这种方式下数据流会被同时发送到Bolt的所有任务中（也就是说同一个元组会被复制多份然后被所有的任务处理），使用这种分组方式要特别小心。 Global grouping：全局分组。这种方式下所有的数据流都会被发送到 Bolt 的同一个任务中，也就是id最小的那个任务。 None grouping：无分组。使用这种方式说明你不关心数据流如何分组。目前这种方式的结果与随机分组完全等效，不过未来Storm社区可能会考虑通过非分组方式来让 Bolt 和它所订阅的 Spout 或 Bolt 在同一个线程中执行。 Direct grouping：直接分组。这是一种特殊的分组方式。使用这种方式意味着元组的发送者可以指定下游的哪个任务可以接收这个元组。只有在数据流被声明为直接数据流时才能够使用直接分组方式。使用直接数据流发送元组需要使用OutputCollector的其中一个emitDirect方法。Bolt可以通过TopologyContext来获取它的下游消费者的任务id，也可以通过跟踪OutputCollector的emit方法（该方法会返回它所发送元组的目标任务的id）的数据来获取任务 id。 Local or shuffle grouping：本地或随机分组。如果目标bolt有一个或者多个task与源bolt的task在同一个工作进程中，tuple将会被随机发送给这些同进程中的tasks。否则，和普通的Shuffle Grouping行为一致。 其中Shuffle grouping、Fields grouping、All grouping、Global grouping四种策略用得较多。 实例拿最简单的WordCount来做例子： 新建wordcount项目新建RandomSentenceSpout类来产生数据1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package com.topo;import org.apache.storm.spout.SpoutOutputCollector;import org.apache.storm.task.TopologyContext;import org.apache.storm.topology.OutputFieldsDeclarer;import org.apache.storm.topology.base.BaseRichSpout;import org.apache.storm.tuple.Fields;import org.apache.storm.tuple.Values;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.Map;import java.util.Random;public class RandomSentenceSpout extends BaseRichSpout &#123; private static final long serialVersionUID = 6102239192526611945L; private static final Logger LOGGER = LoggerFactory.getLogger(RandomSentenceSpout.class); private SpoutOutputCollector collector; private Random random; /** * 当一个Task被初始化的时候会调用此open方法, * 一般都会在此方法中对发送Tuple的对象SpoutOutputCollector和配置对象TopologyContext初始化 */ public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) &#123; this.collector = collector; this.random = new Random(); &#125; /** * 这个spout类，之前说过，最终会运行在task中，某个worker进程的某个executor线程内部的某个task中 * 那个task会负责去不断的无限循环调用nextTuple()方法 * 只要的话呢，无限循环调用，可以不断发射最新的数据出去，形成一个数据流 */ public void nextTuple() &#123; String[] sentences = new String[]&#123; &quot;I used to watch her from my kitchen widow&quot; , &quot;she seemed so small as she muscled her way through the crowd of boys on the playground&quot; , &quot;The school was across the street from our home and I would often watch the kids as they played during recess&quot; , &quot;A sea of children, and yet tome&quot; , &quot;she stood out from them all&quot;&#125;; String sentence = sentences[random.nextInt(sentences.length)]; LOGGER.info(&quot; --- 发射 sentence 数据 ---&gt; &#123;&#125;&quot;, sentence); // 这个values，你可以认为就是构建一个tuple,tuple是最小的数据单位，无限个tuple组成的流就是一个stream,通过 emit 发送数据到下游bolt tuple this.collector.emit(new Values(sentence)); &#125; /** * 用于声明当前Spout的Tuple发送流的域名字。Stream流的定义是通过OutputFieldsDeclare.declareStream方法完成的 * 通俗点说法：就是这个方法是定义一个你发射出去的每个tuple中的每个field的名称是什么，作为下游 bolt 中 execute 接收数据 key */ public void declareOutputFields(OutputFieldsDeclarer declarer) &#123; declarer.declare(new Fields(&quot;sentence&quot;)); &#125;&#125; 新建SplitSentenceBolt类用来切割单词1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.topo;import org.apache.storm.task.OutputCollector;import org.apache.storm.task.TopologyContext;import org.apache.storm.topology.OutputFieldsDeclarer;import org.apache.storm.topology.base.BaseRichBolt;import org.apache.storm.tuple.Fields;import org.apache.storm.tuple.Tuple;import org.apache.storm.tuple.Values;import java.util.Map;public class SplitSentenceBolt extends BaseRichBolt &#123; private static final long serialVersionUID = -4758047349803579486L; private OutputCollector collector; /** * 当一个Task被初始化的时候会调用此prepare方法,对于bolt来说，第一个方法，就是prepare方法 * OutputCollector，这个也是Bolt的这个tuple的发射器,一般都会在此方法中对发送Tuple的对象OutputCollector初始化 */ public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) &#123; this.collector = collector; &#125; /** * 这是Bolt中最关键的一个方法，对于Tuple的处理都可以放到此方法中进行。具体的发送也是通过emit方法来完成的 * 就是说，每次接收到一条数据后，就会交给这个executor方法来执行 * 切分单词 */ public void execute(Tuple input) &#123; // 接收上游数据 String sentence = input.getStringByField(&quot;sentence&quot;); String[] words = sentence.split(&quot; &quot;); for(String word : words)&#123; //发射数据 this.collector.emit(new Values(word)); &#125; &#125; /** * 用于声明当前bolt的Tuple发送流的域名字。Stream流的定义是通过OutputFieldsDeclare.declareStream方法完成的 * 通俗点说法：就是这个方法是定义一个你发射出去的每个tuple中的每个field的名称是什么，作为下游 bolt 中 execute 接收数据 key * 定义发射出去的tuple，每个field的名称 */ public void declareOutputFields(OutputFieldsDeclarer declarer) &#123; declarer.declare(new Fields(&quot;word&quot;)); &#125;&#125; 新建WordCountBolt类用来单词计数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.topo;import org.apache.storm.shade.com.google.common.collect.Maps;import org.apache.storm.task.OutputCollector;import org.apache.storm.task.TopologyContext;import org.apache.storm.topology.OutputFieldsDeclarer;import org.apache.storm.topology.base.BaseRichBolt;import org.apache.storm.tuple.Fields;import org.apache.storm.tuple.Tuple;import org.apache.storm.tuple.Values;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.Map;public class WordCountBolt extends BaseRichBolt &#123; private static final Logger LOGGER = LoggerFactory.getLogger(WordCountBolt.class); private static final long serialVersionUID = -7114915627898482737L; private OutputCollector collector; Map&lt;String,Long&gt; countMap = Maps.newConcurrentMap(); /** * 当一个Task被初始化的时候会调用此prepare方法,对于bolt来说，第一个方法，就是prepare方法 * OutputCollector，这个也是Bolt的这个tuple的发射器,一般都会在此方法中对发送Tuple的对象OutputCollector初始化 */ public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) &#123; this.collector = collector; &#125; /** * 这是Bolt中最关键的一个方法，对于Tuple的处理都可以放到此方法中进行。具体的发送也是通过emit方法来完成的 * 就是说，每次接收到一条数据后，就会交给这个executor方法来执行 * 统计单词 */ public void execute(Tuple input) &#123; // 接收上游数据 String word = input.getStringByField(&quot;word&quot;); Long count = countMap.get(word); if(null == count)&#123; count = 0L; &#125; count ++; countMap.put(word, count); LOGGER.info(&quot; --- 单词计数[&#123;&#125;] ---&gt; 出现的次数：&#123;&#125;&quot;, word, count); //发射数据 this.collector.emit(new Values(word,count)); &#125; /** * 用于声明当前bolt的Tuple发送流的域名字。Stream流的定义是通过OutputFieldsDeclare.declareStream方法完成的 * 通俗点说法：就是这个方法是定义一个你发射出去的每个tuple中的每个field的名称是什么，作为下游 bolt 中 execute 接收数据 key * 定义发射出去的tuple，每个field的名称 */ public void declareOutputFields(OutputFieldsDeclarer declarer) &#123; declarer.declare(new Fields(&quot;word&quot;,&quot;count&quot;)); &#125;&#125; 新建WordCountTopology类用来链接Spout和Bolt，执行主程序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package com.topo;import org.apache.storm.Config;import org.apache.storm.LocalCluster;import org.apache.storm.StormSubmitter;import org.apache.storm.topology.TopologyBuilder;import org.apache.storm.utils.Utils;public class WordCountTopology &#123; public static void main(String[] args) &#123; //去将spout和bolts组合起来，构建成一个拓扑 TopologyBuilder builder = new TopologyBuilder(); // 第一个参数的意思，就是给这个spout设置一个名字 // 第二个参数的意思，就是创建一个spout的对象 // 第三个参数的意思，就是设置spout的executor有几个 builder.setSpout(&quot;RandomSentence&quot;, new RandomSentenceSpout(), 2); builder.setBolt(&quot;SplitSentence&quot;, new SplitSentenceBolt(), 5) //为bolt 设置 几个task .setNumTasks(10) //设置流分组策略 .shuffleGrouping(&quot;RandomSentence&quot;); // fieldsGrouping 这个很重要，就是说，相同的单词，从SplitSentenceSpout发射出来时，一定会进入到下游的指定的同一个task中 // 只有这样子，才能准确的统计出每个单词的数量 // 比如你有个单词，hello，下游task1接收到3个hello，task2接收到2个hello // 通过fieldsGrouping 可以将 5个hello，全都进入一个task builder.setBolt(&quot;wordCount&quot;, new WordCountBolt(), 10) //为bolt 设置 几个task .setNumTasks(20) //设置流分组策略 .shuffleGrouping(&quot;SplitSentence&quot;); //.globalGrouping(&quot;SplitSentence&quot;); //.allGrouping(&quot;SplitSentence&quot;); //.fieldsGrouping(&quot;SplitSentence&quot;, new Fields(&quot;word&quot;)); // 运行配置项 Config config = new Config(); //说明是在命令行执行，打算提交到storm集群上去 if(args != null &amp;&amp; args.length &gt; 0)&#123; /** * 要想提高storm的并行度可以从三个方面来改造 * worker(进程)&gt;executor(线程)&gt;task(实例) * 增加work进程，增加executor线程，增加task实例 * 对应 supervisor.slots.port 中配置个数 * 这里可以动态设置使用个数 * 最好一台机器上的一个topology只使用一个worker,主要原因时减少了worker之间的数据传输 * * 注意：如果worker使用完的话再提交topology就不会执行，因为没有可用的worker，只能处于等待状态，把之前运行的topology停止一个之后这个就会继续执行了 */ config.setNumWorkers(3); try &#123; // 将Topolog提交集群 StormSubmitter.submitTopology(args[0], config, builder.createTopology()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;else&#123; // 用本地模式运行1个拓扑时，用来限制生成的线程的数量 config.setMaxTaskParallelism(20); // 将Topolog提交本地集群 LocalCluster cluster = new LocalCluster(); cluster.submitTopology(&quot;wordCountTopology&quot;, config, builder.createTopology()); // 为了测试模拟等待 Utils.sleep(60000); // 执行完毕，关闭cluster cluster.shutdown(); &#125; &#125;&#125; 运行结果shuffleGrouping运行结果 shuffleGrouping运行结果 随机分组，不自觉间做到了负载均衡。 globalGrouping运行结果 globalGrouping运行结果 只往一个里面发,发送到id最小的那个任务。 allGrouping运行结果 allGrouping运行结果 两个spot并行 所有都分发。 fieldsGrouping运行结果 fieldsGrouping运行结果 相同的名称的fields分发到一个bolt里面。","tags":[{"name":"Storm","slug":"Storm","permalink":"http://www.duanmuxu.top/tags/Storm/"},{"name":"大数据","slug":"大数据","permalink":"http://www.duanmuxu.top/tags/大数据/"}]},{"title":"Ambari集群搭建（HDP离线安装版）","date":"2019-06-04T10:57:20.241Z","path":"20190604/ambari-cluster-setup-hdp-offline-installation.html","text":"安装环境部署使用版本 Ubuntu：ubuntu-16.04.6-server-amd64 Ambari：ambari-2.5.0.3-ubuntu16 HDP：HDP-2.6.0.3-ubuntu16 HDP-UTILS：HDP-UTILS-1.1.0.21-ubuntu16 设置每台主机的host首先修改每一台主机的hostname输入命令： 1vim /etc/hostname 命名随意，不重复就行。 输入命令： 1vim /etc/hosts 进入hosts编辑页面每台主机host的配置都要相同 1234# 127.0.0.1 localhost ambari01192.168.2.93 ambari01192.168.2.94 ambari02192.168.2.95 ambari03 ip地址后的名称与hostname中的名称相同 修改完后ping其他不同的主机，看能不能ping通 链接Xshell安装Ubuntu的时候，勾选安装OpenSSH，系统打开后就能直接使用ssh服务了。 登录每台主机，输入命令： 1vim /etc/ssh/sshd_config 将该文件下的 PermitRootLogin的值改为 yes 输入以下命令重启一下SSH服务： 1/etc/init.d/ssh restart 重启成功后就能使用xShell连接虚拟机进行操作了。 免密登录从机首先在主机上运行 sudo ssh-keygen ，然后一路回车，生成本机公私密钥。 注意要一路回车，不用输入任何字符。 然后执行以下命令： 123ssh-copy-id root@ambari01ssh-copy-id root@ambari02ssh-copy-id root@ambari03 注意也要对自己本机也操作一次，不然后面在ambari服务器上安装组件的时候本机会显示permision denied 的情况。 执行以上命令时，会依次提示输入每台从机的root密码，然后主机就会自动将公钥发送给各个从机的机器中并立即生效。 执行后可以通过执行ssh root@ambari02 进行测试，可以直接登陆从机，无需密码。 保存主机的私钥复制一份刚才主机生成的私钥，后面ambari搭建集群的时候会需要用到，密钥的文件位于 /root/.ssh/id_rsa，执行以下命令： 1cp /root/.ssh/id_rsa /root 将密钥复制到root文件目录下，然后通过xftp将文件下载到Windows本地。因为xftp不能直接访问.ssh目录。 安装yum和ntp每个从机、主机都需要安装yum、ntp，否则后面Ambari部署有些会不通过。 12apt-get install yumapt-get install ntp python版本 &gt; 2.6一般Ubuntu默认都会安装python2.7，此条可以忽略。 准备工作完毕。下面开始集群的搭建。 下载HDP与HDP-UTILS离线安装包前面一个安装包大约5.9G，如果选择在线安装则太费时间，因此下载已经编译好的HDP安装包进行离线安装。 首先进入 https://docs.hortonworks.com/ 找到ambari，选择自己想要的版本。本文使用的是Ambari-2.5.0.3版本。选择好版本后，找到Apache Ambari Installation ，点击进入后，通过点击 Getting Ready -&gt; Using a Local Repository -&gt; Obtaining the Repositories -&gt; HDP Stack Repositories 找到HDP离线版下载，我使用的版本为 HDP-2.6.0.3，具体网址为下： 1https://docs.hortonworks.com/HDPDocuments/Ambari-2.5.0.3/bk_ambari-installation/content/hdp_26_repositories.html 然后就是漫长的下载之路了，一共6G左右，记住要选择对应的Ambari和虚拟机版本。下载HDP和HDP-UTILS两个文件。 安装 AmbariAmbari只需要在主机上安装，而后安装组件时其他从机会自动部署。 继续在刚才的网站上，找到 Download the Ambari Repository，选择对应的虚拟机版本，然后按照官方手册指引，root用户登录主机后依次执行以下三句命令即可完成安装源的配置。 123wget -O /etc/apt/sources.list.d/ambari.list http://public-repo-1.hortonworks.com/ambari/ubuntu16/2.x/updates/2.5.0.3/ambari.listapt-key adv --recv-keys --keyserver keyserver.ubuntu.com B9733A7A07513CADapt-get update 要注意ambari版本的问题，不要版本不一致。 具体操作可以查看官方操作手册。 然后进行ambari-server 的安装 1apt-get install ambari-server 一共七百多MB，大概安装个二十分钟左右，视网速而定。 配置 Ambari执行命令 1ambari-server setup 进行配置ambari-server，一路回车进行配置，途中会安装JDK，选择JDK1.8继续安装。 中途也会遇到选择安装数据库，默认选择安装MySQL，继续安装。 ambari的用户名和密码如果不进行设置则默认都为admin。 安装好后将JDK1.8安装包发送给每个从机，都将JDK1.8安装一遍。 启动 Ambari操作手册上如是说： 12345678- Run the following command on the Ambari Server host:ambari-server start- To check the Ambari Server processes:ambari-server status- To stop the Ambari Server:ambari-server stop 执行 ambari-server start ，稍候片刻启动服务。然后进入网址 http://&lt;主机IP&gt;:8080 就可以进入Ambari的登录界面。账号密码如果刚才没有配置，则均为admin。 部署HDP离线安装包安装Nignx也不一定是要nignx，只要能提供Http服务，来作为HDP离线包的下载服务器就行。 主机上运行： 1apt-get install nignx 安装完成后浏览器进入 http://&lt;主机IP&gt;:80 查看是否有Nignx欢迎页面。 上传HDP离线安装包使用xftp进行文件传输，xftp连接主机后进入 /var/www/html 目录，将HDP-UTILS-1.1.0.21-ubuntu16.tar.gz和HDP-2.6.0.3-ubuntu16-deb.tar.gz两个文件传到该目录下。 在linux终端下新建文件夹HDP-UTILS-1.1.0.21，将压缩包HDP-2.6.0.3-ubuntu16-deb.tar.gz直接解压，将压缩包HDP-UTILS-1.1.0.21-ubuntu16.tar.gz解压到新建的文件夹HDP-UTILS-1.1.0.21下 执行以下命令将默认的欢迎页面重命名： 1mv /var/www/html/index.nginx-debian.html /var/www/html/index.nginx-debian.html.bak 进入nignx的配置页面 1vim /etc/nginx/sites-enabled/default 在 server{…} 里添加一句 autoindex on; 即打开目录浏览功能。 以上步骤做完后，再次访问 http://&lt;主机IP&gt;:80 时，能看到目录结构，同时能找到HDP以及HDP-UTILS，能够从页面上下载，HDP离线安装包就配置好了。 开始创建集群 进入 http://&lt;主机IP&gt;:8080 Ambari登录页面，账号密码均为admin； ambari登录界面 登陆后选择Launch Install Wizard； 在这里插入图片描述 命名你的集群，好听点就行； 下一步，选择本地Repository，选择对应的虚拟机版本，链接填刚才配置好的Nignx的服务器路径址，即http://&lt;主机IP&gt;/HDP/ubuntu16/ 和 http://&lt;主机IP&gt;/HDP-UTILS-1.1.0.21/； 在这里插入图片描述 进入install options，输入集群机器的ip，选择之前下载到本地的id_rsa文件。点击Register and confirm 进入下一步； 在这里插入图片描述 confirm host 之后，进行选择服务，即要安装的大数据组件，进行安装 进行到Customize Services时可能会让你进行一些密码的设置，比如hive组件之类的，设置好不报错后继续安装； 在这里插入图片描述 安装成功即完成部署。 在这里插入图片描述 完结撒花！ 在这里插入图片描述 参考文章：如何优雅地使用Apache Ambari安装HDFS、HBase等分布式应用","tags":[{"name":"大数据","slug":"大数据","permalink":"http://www.duanmuxu.top/tags/大数据/"},{"name":"Ambari","slug":"Ambari","permalink":"http://www.duanmuxu.top/tags/Ambari/"}]},{"title":"罗马数字转化为阿拉伯数字","date":"2019-06-02T04:28:32.282Z","path":"20190602/roman-numerals-are-converted-to-arabic.html","text":"题目简述： Roman numerals are represented by seven different symbols: I, V, X, L, C, D and M. Symbol Value I 1 V 5 X 10 L 50 C 100 D 500 M 1000 For example, two is written as II in Roman numeral, just two one’s added together. Twelve is written as, XII, which is simply X + II. The number twenty seven is written as XXVII, which is XX + V + II. Roman numerals are usually written largest to smallest from left to right. However, the numeral for four is not IIII. Instead, the number four is written as IV. Because the one is before the five we subtract it making four. The same principle applies to the number nine, which is written as IX. 简而言之，从I到M七个字母分别代表着1~1000的七种不同大小。当所给罗马数字的字母顺序为从M到I的顺序排列时，它的值即为其字母所代表的值相加，比如’XXVII’，即表示X+X+V+I+I。当所给罗马数字字符串中有一个字母比这个字母其后的字母所表示的值小时，这两个字母结合起来代表一个数值，其值为（后一个字母的值-前一个字母的值），比如’MCD’，C的值比D小，因此等于M+CD=1000+500-100=1400。 解题思路其实经过分析过后思路就很明确了，比较所给字符串中当前字母和下一个字母的数值大小，如果当前字母的值比下一个字母的值大，直接相加，反之则后一个字母的值减去当前字母的值，并将这两个字母当作一个整体。 有了思路，就得有解题方法。既然是涉及到前后两个字母进行比较，那么就有两种情况，一种是获取当前字母的值，与后一个字母进行比较；一种是保存前一个字母的值，与当前字母的值进行比较。 当前字母与前一个字母相比较1234567891011121314151617181920212223class Solution &#123; public int romanToInt(String s) &#123; int[] a = new int[26]; a[&apos;I&apos; - &apos;A&apos;] = 1; a[&apos;V&apos; - &apos;A&apos;] = 5; a[&apos;X&apos; - &apos;A&apos;] = 10; a[&apos;L&apos; - &apos;A&apos;] = 50; a[&apos;C&apos; - &apos;A&apos;] = 100; a[&apos;D&apos; - &apos;A&apos;] = 500; a[&apos;M&apos; - &apos;A&apos;] = 1000; int sum = 0; char prev = &apos;A&apos;; for (char str : s.toCharArray()) &#123; if(a[str - &apos;A&apos;] &gt; a[prev - &apos;A&apos;])&#123; sum = sum - 2*a[prev - &apos;A&apos;]; &#125; sum = sum + a[str - &apos;A&apos;]; prev = str; &#125; return sum; &#125;&#125; 这种方法foreach中，当前值为str，保存的前一个字母为prev。当当前字母的值大于前一个字母的值时，整体总数sum减去前一个字母的值的两倍（一倍拿来消除之前加过的前一个字母的值，一倍拿来做整体两个字母的减数）。从而得出结果。 当前字母与后一个字母相比较12345678910111213141516171819202122class Solution &#123; public int romanToInt(String s) &#123; HashMap&lt;Character, Integer&gt; chara = new HashMap&lt;&gt;(); chara.put(&apos;I&apos;, 1); chara.put(&apos;V&apos;, 5); chara.put(&apos;X&apos;, 10); chara.put(&apos;L&apos;, 50); chara.put(&apos;C&apos;, 100); chara.put(&apos;D&apos;, 500); chara.put(&apos;M&apos;, 1000); int sum = 0; //定义总数 for(int i = 0; i &lt; s.length(); i++)&#123; if(i &lt; s.length()-1 &amp;&amp; chara.get(s.charAt(i)) &lt; chara.get(s.charAt(i+1)))&#123; sum = sum - chara.get(s.charAt(i)); &#125;else&#123; sum = sum + chara.get(s.charAt(i)); &#125; &#125; return sum; &#125;&#125; 使用Map进行存储，当时使用数组也可以，只是为了存储多元化。这种方法要注意charAt的界限，防止越界。当当前的字母的值大于下一个字母的值时，正常相加；反之则总数sum减去当前字母的值。 有一点值得注意的是if的条件中有个i &lt; s.length()-1，即为了防止越界我们作比较只比较到了字符串的倒数第二个字母，最后一个字母的值是直接相加的。因为最后一个字母无需与其后的字母相比较，因此此种方法可行。","tags":[{"name":"算法","slug":"算法","permalink":"http://www.duanmuxu.top/tags/算法/"},{"name":"数据结构","slug":"数据结构","permalink":"http://www.duanmuxu.top/tags/数据结构/"},{"name":"leetcode","slug":"leetcode","permalink":"http://www.duanmuxu.top/tags/leetcode/"}]},{"title":"两个字符串中含有几个相同字符的几种解法","date":"2019-06-02T04:28:32.281Z","path":"20190602/several-solutions-for-identical-characters-in-two-strings.html","text":"最近为了暑期实习面试开始复习数据结构与算法，作为一个大三的软件工程的学生，在大三下学期才开始接触算法练习平台，真够不好意思的。进入正题，题目如下： You’re given strings J representing the types of stones that are jewels, and S representing the stones you have. Each character in S is a type of stone you have. You want to know how many of the stones you have are also jewels.The letters in J are guaranteed distinct, and all characters in J and S are letters. Letters are case sensitive, so “a” is considered a different type of stone from “A”.Example 1:Input: J = “aA”, S = “aAAbbbb”Output: 3Example 2:Input: J = “z”, S = “ZZ”Output: 0Note:S and J will consist of letters and have length at most 50.The characters in J are distinct. 简单理解就是给定两个字符串J和S，S字符串中有多少个字母是J字符串中的字母，并且要区分大小写。 以下方法全是基于Java进行实现 先放我的方法： 方法一：将字符串转化成数组1234567891011121314class Solution &#123; public int numJewelsInStones(String J, String S) &#123; char[] Ja = J.toCharArray(); char[] Sa = S.toCharArray(); int r = 0; for (int i = 0;i &lt; Ja.length ; i ++)&#123; for(int j = 0; j &lt; Sa.length; j++)&#123; if(Ja[i] == Sa[j]) r ++; &#125; &#125; return r; &#125;&#125; 先将J和S字符串转化成两个数组 对J的数组进行遍历，再对S的数组进行遍历 如果J中的字母与S中的字母相等（区分大小写），累加器r就加一 最后输出r即可 &nbsp;&nbsp;&nbsp;&nbsp;很简单的一道题，当时想着继续刷题吧，反正刷题网站的意义就在于刷刷刷。不过还好打开了这道题的评论区，让我看到了一个新的世界。评论里有着许许多多其他不同的解题方法。这才是刷题网站的意义，**给一道题以不同的解题思路，让每个人都能有多种不同的思考。** &nbsp;&nbsp;&nbsp;&nbsp;以下是本道题评论区中给出的其他解题方法，亲测有效 方法二：字符串直接进行比较12345678910111213class Solution &#123; public int numJewelsInStones(String J, String S)&#123; int count=0; for (int i=0;i&lt;J.length();i++)&#123; for (int j=0;j&lt;S.length();j++)&#123; if (S.charAt(j) == J.charAt(i))&#123; count+=1; &#125; &#125; &#125; return count; &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;其实和方法一差不大多，直接对字符串进行循环比较。最开始我也想用这方法，不过忘了charAt方法，不能确定字符串某个位置上的字母，于是换成了方法一。&nbsp;&nbsp;&nbsp;&nbsp;另一种直接比较方法 1234567891011class Solution &#123; public int numJewelsInStones(String J, String S) &#123; int count =0; for (int i =0;i&lt;S.length();i++)&#123; if (J.contains(String.valueOf(S.charAt(i))))&#123; count++; &#125; &#125; return count; &#125;&#125; 也是循环比较，少了层for循环而已，不再赘述。 方法三：正则表达式123public int numJewelsInStones(String J, String S) &#123; return S.replaceAll(&quot;[^&quot; + J + &quot;]&quot;, &quot;&quot;).length();&#125; 太狠了，这方法太狠了，一行解决事情。先介绍一下什么是正则表达式： 正则表达式是对字符串（包括普通字符（例如，a到z之间的字母）和特殊字符（称为“元字符”））操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。正则表达式是一种文本模式，模式描述在搜索文本时要匹配的一个或多个字符串。 判断S字符串中有多少能被J字符串所替换的字符，将这些字符的长度输出就是答案。太狠了。不过这种方法时间会占用更多。 方法四：Hash Set方法123456789101112class Solution &#123; public int numJewelsInStones(String J, String S) &#123; Set&lt;Character&gt; set = new HashSet&lt;&gt;(); for (char c : J.toCharArray()) set.add(c); int res = 0; for (char c : S.toCharArray()) if (set.contains(c)) res++; return res; &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;Hash Set就是用来提高查找效率的，将J字符串中的字母放在set中，判断S字符串中的字母知否包含在set中，是则累加器res加一，最后输出。这种方法运行效率也高。 问：为什么不是将S字符串的字符存入set中？答：Hash Set不能存入相同的元素。以例子一为例，S字符串为：S = “aAAbbbb”，”A”有两个，”b”有四个，最后存入set后，set的长度为3，即存入元素为”a”,”A,”b”，因为字符串直接存入set里时，相同元素的HashCode是一样的，就会跳过重复的字符。这时与J字符串相比较，就只有”a”,”A”相匹配，输出结果为2，答案错误。 方法五：ASCII值转换123456789public int numJewelsInStones(String J, String S) &#123; int count = 0; int[] arr = new int[&apos;z&apos; - &apos;A&apos; + 1]; for (char c : J.toCharArray()) arr[c - &apos;A&apos;] = 1; for (char c : S.toCharArray()) count += arr[c - &apos;A&apos;]; return count;&#125; &nbsp;&nbsp;&nbsp;&nbsp;创建一个arr数组，大小为A的ASCII的值（65）到z的ASCII的值（122）的范围，中间有些特殊字符也占用了空间，不过没关系，不碍事。然后将J字符串中的字符也转成ASCII值，并将以该字符的ASCII值（与A相减过后的值，不然会溢出）为角标的数组值设为1，再对S字符串进行循环，累加器count一直与角标为S串中的字符的ASCII值的arr数组的值相加，最后结果输出即可。也是一种转换思维。 方法六：Hash Map方法1234567891011public int numJewelsInStones(String J, String S) &#123; Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); int count = 0; for(char s : S.toCharArray()) map.put(s, map.getOrDefault(s, 0) + 1); for(int i = 0; i &lt; J.length(); i++) count += map.getOrDefault(J.charAt(i), 0); return count; &#125; HashSet方法更简洁，详情参见方法四。 暂时放这一些方法，有看到新的再更新，继续学习！","tags":[{"name":"字符串","slug":"字符串","permalink":"http://www.duanmuxu.top/tags/字符串/"},{"name":"算法","slug":"算法","permalink":"http://www.duanmuxu.top/tags/算法/"},{"name":"数据结构","slug":"数据结构","permalink":"http://www.duanmuxu.top/tags/数据结构/"},{"name":"leetcode","slug":"leetcode","permalink":"http://www.duanmuxu.top/tags/leetcode/"}]},{"title":"链表中倒数第k个结点","date":"2019-06-02T04:28:32.279Z","path":"20190602/the-kth-node-in-list.html","text":"题目描述： 输入一个链表，输出该链表中倒数第k个结点。 链表结构如下： 12345678public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125; 由链表结构就能知道由此基础建立的链表不能直接知道该链表的长度，需要通过node = node.next 一步一步遍历链表才能获取链表长度。 因此最先想到的方法就是先遍历一遍链表，获取链表长度，然后通过链表长度和k数值的差得出目标地址。实现方法如下： 1234567891011121314151617181920public class Solution &#123; public ListNode FindKthToTail(ListNode head,int k) &#123; ListNode newHead = head, pre = head; int count = 0; // 获取链表长度 while(pre != null)&#123; count++; pre = pre.next; &#125; if(count &lt; k) // 不存在倒数第k个链表 return null; else&#123; int num = count - k; // num为正数的目的地址，与倒数第k个链表值一致 while(num &gt; 0)&#123; newHead = newHead.next; num--; &#125; return newHead; &#125; &#125;&#125; 有了基础思路，下一步就是简化代码，用更简洁的表达将效果呈现出来。以下使用for循环： 12345678910111213public class Solution &#123; public ListNode FindKthToTail(ListNode head,int k) &#123; //5,&#123;1,2,3,4,5&#125; ListNode p, q; p = q = head; int i = 0; for (; p != null; i++) &#123; if (i &gt;= k) q = q.next; p = p.next; // p相当于上面的pre链表，用于测量链表长度 &#125; return i &lt;= k ? null : q; &#125;&#125; 也可以使用while一次遍历： 1234567891011121314151617181920212223242526public class Solution &#123; public ListNode FindKthToTail(ListNode head,int k) &#123; ListNode pre=null,p=null; //两个指针都指向头结点 p=head; pre=head; //记录k值 int a=k; //记录节点的个数 int count=0; //p指针先跑，并且记录节点数，当p指针跑了k-1个节点后，pre指针开始跑， //当p指针跑到最后时，pre所指指针就是倒数第k个节点 while(p!=null)&#123; p=p.next; count++; if(k&lt;1)&#123; pre=pre.next; &#125; k--; &#125; //如果节点个数小于所求的倒数第k个节点，则返回空 if(count&lt;a) return null; return pre; &#125;&#125; 其实思路是一致的，就是通过得到链表长度，再得到n-k位置的链表值。","tags":[{"name":"算法","slug":"算法","permalink":"http://www.duanmuxu.top/tags/算法/"},{"name":"数据结构","slug":"数据结构","permalink":"http://www.duanmuxu.top/tags/数据结构/"},{"name":"leetcode","slug":"leetcode","permalink":"http://www.duanmuxu.top/tags/leetcode/"}]},{"title":"括号匹配消除","date":"2019-06-02T04:28:32.278Z","path":"20190602/bracket-matching-elimination.html","text":"题目描述： Given a string containing just the characters ‘(‘, ‘)’, ‘{‘, ‘}’, ‘[‘ and ‘]’, determine if the input string is valid. An input string is valid if: Open brackets must be closed by the same type of brackets. Open brackets must be closed in the correct order. Note that an empty string is also considered valid. input : ()[]{}output : true input : ({[]})output : true input : ({)}output : false 简单得说就是括号相匹配，同一个类型的括号连在一起。同一对括号可以嵌套在其他括号中，但只能一对括号都嵌套进去（如（{}）），不能只嵌套一边的括号（如（{）}）。 有看过二叉树的前中后序遍历进行加减乘除操作的应该一看到这一题就知道怎么做了。运算中有有括号的先算括号中的数的原则，那么就需要对运算中的括号进行识别与约束，与这道题一个道理。因此一看到这道题就应该想到可以用栈去求解。解法如下： 使用栈(Stack)的解法1234567891011121314151617181920212223class Solution &#123; public boolean isValid(String s) &#123; Stack&lt;Character&gt; stack = new Stack&lt;&gt;(); for (Character chara:s.toCharArray()) &#123; if (chara == &apos;(&apos; || chara == &apos;[&apos; || chara == &apos;&#123;&apos;) stack.push(chara); else &#123; if (stack.isEmpty())&#123; return false; &#125;else &#123; Character charPop = stack.pop(); if (charPop == &apos;(&apos; &amp;&amp; chara != &apos;)&apos; || charPop == &apos;[&apos; &amp;&amp; chara != &apos;]&apos; || charPop == &apos;&#123;&apos; &amp;&amp; chara != &apos;&#125;&apos;)&#123; return false; &#125; &#125; &#125; &#125; if (stack.isEmpty()) return true; else return false; &#125;&#125; 思路：所给字符串第一个字符必为”(“,”[“,”{“中的一种，如果不是，那必然无法必配成功，return false。按字符串顺序识别字符将字符串push进栈中。当字符为”)”,”]”,”}”中的一种时，pop一个字符与上面三种字符向匹配，如果匹配成功，继续执行程序，匹配成功的括号自动消除。反之return false，说明这个“右”括号的前面一个括号也是“右”括号，即前面一个括号无法匹配成功。最后判断这个栈是否为空，如果全部都匹配消除完成，栈为空。 优化后的使用栈的方法1234567891011121314public boolean isValid(String s) &#123; Stack&lt;Character&gt; stack = new Stack&lt;Character&gt;(); for (char c : s.toCharArray()) &#123; if (c == &apos;(&apos;) stack.push(&apos;)&apos;); else if (c == &apos;&#123;&apos;) stack.push(&apos;&#125;&apos;); else if (c == &apos;[&apos;) stack.push(&apos;]&apos;); else if (stack.isEmpty() || stack.pop() != c) return false; &#125; return stack.isEmpty();&#125; 太简洁了！！！ 字符如果是“左”括号，那么栈中保存相应的“右”括号。字符如果是“右”括号，与pop出的值相比，如果不相等则说明前一个括号不是相对应的“左”括号，即无法匹配，return false。 除了上面用栈的方法外，还有一种值替换法，实现如下： 目标值替换法123456789101112public class Solution &#123; public boolean isValid(String s) &#123; int length; do &#123; length = s.length(); s = s.replace(&quot;()&quot;, &quot;&quot;).replace(&quot;&#123;&#125;&quot;, &quot;&quot;).replace(&quot;[]&quot;, &quot;&quot;); &#125; while(length != s.length()); return s.length() == 0; &#125;&#125; 思路：暴力替换目标值，符合一整对括号的值直接替换成空值，以替换前的字符串长度和替换后的字符串长度作比较条件，建立循环。最后判断字符串长度是否为零，即整对括号是否被替换完全。 还有Map的方法： 使用Key-Value匹配进行求解123456789101112131415161718public boolean isValid(String s) &#123; char[] chars = s.toCharArray(); Map&lt;Character,Character&gt; pairs = new HashMap&lt;Character,Character&gt;(); pairs.put(&apos;(&apos;, &apos;)&apos;); pairs.put(&apos;&#123;&apos;, &apos;&#125;&apos;); pairs.put(&apos;[&apos;, &apos;]&apos;); Stack&lt;Character&gt; stack = new Stack&lt;Character&gt;(); for (char c:chars) &#123; if (pairs.containsKey(c)) &#123; stack.push(pairs.get(c)); &#125; else &#123; if (stack.isEmpty() || c != stack.pop()) return false; &#125; &#125; return stack.isEmpty();&#125; 思路：将“左”括号作为key，“右”括号作为值放在Map中，其他思路与优化后的使用栈的方法一致。 无论是用栈还是数组还是Hash Map，都只是一种工具，最主要的是思路，有了思路就有了目标，各种存储方法只是帮助达到目标的工具罢了。（当然，有些工具是独轮车，有些工具是飞机哈哈哈哈哈哈哈）","tags":[{"name":"算法","slug":"算法","permalink":"http://www.duanmuxu.top/tags/算法/"},{"name":"数据结构","slug":"数据结构","permalink":"http://www.duanmuxu.top/tags/数据结构/"},{"name":"leetcode","slug":"leetcode","permalink":"http://www.duanmuxu.top/tags/leetcode/"}]},{"title":"反转链表","date":"2019-06-02T04:28:32.276Z","path":"20190602/reverse-list.html","text":"题目描述 输入一个链表，反转链表后，输出新链表的表头。 最开始的思路是保存链表中的每一个值到一个数组中，然后逆序输出到新链表中，暴力反转链表。实现如下： 123456789101112131415161718192021222324class Solution &#123; public ListNode ReverseList(ListNode head) &#123; ArrayList&lt;Integer&gt; array = new ArrayList&lt;&gt;(); ListNode cur = head; ListNode pre, result = new ListNode(0); pre = result; if(head == null)&#123; return result; &#125; while(cur != null)&#123; //循环读取链表数值，存在array链表中 array.add(cur.val); cur = cur.next; &#125; for(int i = array.size() - 1; i &gt;=0; i--)&#123; pre = new ListNode(array.get(i)); pre = pre.next; &#125; return result.next; &#125;&#125; 想法很美好，现实很骨感。运行时报出如下错误： Exception in thread “main” java.lang.NullPointerException 咋肥事，还会有空指针报错？马上Debug，发现一个漏洞。 最开始定义了ListNode pre, result两个新链表，pre用于循环，每次增加新的next节点，因为每次pre.next = new ListNode(num)时，pre.val会赋予新的值，不能成为一条完整的逆序链表，因此定义了result链表来与pre每次添加的值相等，因为result = pre，因此两个内存地址相等，也就是result每次会以链表形式添加pre所添加的新元素，从而达到逆序操作。 不过问题就出在pre = new ListNode(array.get(i));这上，每次new一个值时，pre的内存地址就改变一次，但是result的内存地址不会变，因此result不会与pre产生联系，也就是最后return result的时候，result的值在最开始定义result时就已经确定了，与后续pre的操作无关，因此无法得到反转链表的目的。 所以上述代码是些辣鸡。那就换个思路吧，直接从链表本身入手。实现如下： 123456789101112131415public class Solution &#123; public ListNode ReverseList(ListNode head) &#123; if(head==null) return null; ListNode pre = null; ListNode next = null; while(head!=null)&#123; next = head.next; head.next = pre; pre = head; head = next; &#125; return pre; &#125;&#125; 啥意思呢，pre表示所给链表的前一个节点，next表示所给链表的下一个节点。代码解释如下: next = head.next 表示next保存head的下一个节点，保证head.next不会丢失； head.next = pre 表示head指向了pre,也就是head从后指向前； pre = head 表示pre现在已经是在next前面的数值中，由后指向前的一个链表； head = next 表示head找回原先的head的下一节点，也就是第一步中被next保存的节点； 继续以上操作，直至head遍历完成，此时pre也反转完成。 举个栗子最直观： 输入链表 1-&gt;2-&gt;3-&gt;4-&gt;5 next = head.next = 2-&gt;3-&gt;4-&gt;5 head.next = pre =null pre = head = 1 head = next = 2-&gt;3-&gt;4-&gt;5 —新一轮循环— next = head.next = 3-&gt;4-&gt;5 head.next = pre = 1 （此时head.val = 2，因此head 表示2-&gt;1） pre = head = 2-&gt;1 （达到反转的目的） head = next = 3-&gt;4-&gt;5 —新一轮循环— …… head = null pre = 5-&gt;4-&gt;3-&gt;2-&gt;1 输出链表 5-&gt;4-&gt;3-&gt;2-&gt;1 任务完成，值得品味。","tags":[{"name":"剑指Offer","slug":"剑指Offer","permalink":"http://www.duanmuxu.top/tags/剑指Offer/"},{"name":"算法","slug":"算法","permalink":"http://www.duanmuxu.top/tags/算法/"},{"name":"数据结构","slug":"数据结构","permalink":"http://www.duanmuxu.top/tags/数据结构/"}]},{"title":"对所有员工的薪水按照salary进行按照1-N的排名","date":"2019-06-02T04:28:32.273Z","path":"20190602/salary-for-all-employees-is-ranked-according-to-1n-in.html","text":"题目描述 对所有员工的当前(to_date=’9999-01-01’)薪水按照salary进行按照1-N的排名，相同salary并列且按照emp_no升序排列 建表语句： 123456CREATE TABLE `salaries` (`emp_no` int(11) NOT NULL,`salary` int(11) NOT NULL,`from_date` date NOT NULL,`to_date` date NOT NULL,PRIMARY KEY (`emp_no`,`from_date`)); 输出描述： emp_no salary rank 10005 94692 1 10002 94409 2 10010 94409 2 10001 88958 3 10007 88958 3 10004 74057 4 不看最后一个rank排名，那么这道题特别简单： 1234select s.emp_no, s.salaryfrom salaries swhere s.to_date = &apos;9999-01-01&apos;order by s.salary desc, s.emp_no asc 但是题目偏偏加了一个rank工资排名。那么怎样才能获得这个排名呢？ 在Java中我们可以直接使用循环来给目标值加排名，SQL查询语句中看来行不通。仅仅使用一张表似乎达不到目的，那就使用两张表吧。 既然不能使用循环，那么可以通过什么方法来表示排名，或者说是表示在自己的前面还有多少人（包括自己）。 很明显了，我们可以通过两张表中salary的大小不同来获取在自己前面的人的个数，即s1.salary &lt;= s2.salary。举个栗子：有三个salary（6000，5000，4000， 4000），输出为s1.salary，那么当s1.salary = 6000时，s1.salary &lt;= s2.salary 的值为6000，也就是一个，当s1.salary = 5000时，s1.salary &lt;= s2.salary 的值为6000和5000两个。但是当s1.salary = 4000时，s1.salary &lt;= s2.salary 的值就为（6000，5000，4000， 4000）四个，且4000是重复的，因此我们使用count(distinct s2.salary) rank 来去重，并计算个数，即排名，以此类推，输出s1.salary的情况下，有多少个s2.salary大于等于s1.salary就是s1.salary的排名 当然不要忘了group by s1.emp_no ，用来将员工编号分组，计算count() 最后结果为： 12345select s1.emp_no, s1.salary, count(distinct s2.salary) rankfrom salaries s1, salaries s2where s1.salary &lt;= s2.salary and s1.to_date = &apos;9999-01-01&apos; and s2.to_date = &apos;9999-01-01&apos;group by s1.emp_noorder by rank","tags":[{"name":"数据库","slug":"数据库","permalink":"http://www.duanmuxu.top/tags/数据库/"}]},{"title":"单向链表小记","date":"2019-06-02T04:28:32.272Z","path":"20190602/oneway-linked-list.html","text":"什么是链表？链表（Linked list）是一种常见的基础数据结构，是一种线性表，但是并不会按线性的顺序存储数据，而是在每一个节点里存到下一个节点的指针(Pointer)。 使用链表结构可以克服数组链表需要预先知道数据大小的缺点，链表结构可以充分利用计算机内存空间，实现灵活的内存动态管理。但是链表失去了数组随机读取的优点，同时链表由于增加了结点的指针域，空间开销比较大。 什么是单向链表？单链表是链表中结构最简单的。一个单链表的节点(Node)分为两个部分，第一个部分(data)保存或者显示关于节点的信息，另一个部分存储下一个节点的地址。最后一个节点存储地址的部分指向空值。（其实就是上一篇中提到的ListNode） 单向链表只可向一个方向遍历，一般查找一个节点的时候需要从第一个节点开始每次访问下一个节点，一直访问到需要的位置。而插入一个节点，对于单向链表，我们只提供在链表头插入，只需要将当前插入的节点设置为头节点，next指向原头节点即可。删除一个节点，我们将该节点的上一个节点的next指向该节点的下一个节点。 单向链表的具体实现这边放上练习用的源码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139package LinkedList;import java.util.LinkedList;public class SingleLinkedList &#123; private int size; private Node head; public SingleLinkedList() &#123; size = 0; head = null; &#125; private class Node&#123; private Object data;//每个节点的数据 private Node next; //每个节点指向下一个节点的连接 public Node(Object data) &#123; this.data = data; &#125; &#125; //在链表头添加元素 public Object addhead(Object obj) &#123; Node newHead = new Node(obj); if(size == 0) head = newHead; else &#123; newHead.next = head; head = newHead; &#125; size++; return obj; &#125; //在链表头删除元素 public Object deleteHead() &#123; Object obj = head.data; head = head.next; size--; return obj; &#125; //查找指定元素，找到了返回节点Node，找不到返回null public Node find(Object obj) &#123; Node current = head; int tempSize = size; while(tempSize &gt; 0)&#123; if(obj.equals(current.data))&#123; return current; &#125;else&#123; current = current.next; &#125; tempSize--; &#125; return null; &#125; //删除指定的元素，删除成功返回true public boolean delete(Object value)&#123; if(size == 0)&#123; return false; &#125; Node current = head; Node previous = head; while(current.data != value)&#123; if(current.next == null)&#123; return false; &#125;else&#123; previous = current; current = current.next; &#125; &#125; //如果删除的节点是第一个节点 if(current == head)&#123; head = current.next; size--; &#125;else&#123;//删除的节点不是第一个节点 previous.next = current.next; size--; &#125; return true; &#125; //判断链表是否为空 public boolean isEmpty() &#123; return (size == 0); &#125; //在链表尾部添加元素 public Object addTail(Object obj) &#123; Node newTail = new Node(obj); Node current = head; int temSize = size; while (temSize &gt; 0) &#123; if (current.next == null) &#123; //需要先增加链表的容量，才能进行添加 size++; current.next = newTail; newTail.next = null; return current; &#125;else &#123; current = current.next; &#125; temSize--; &#125; return obj; &#125; //显示节点信息 public void display() &#123; if (size &gt; 0) &#123; Node node = head; int tempSize = size; if (tempSize == 1) &#123; System.out.print(&quot;[&quot; + node.data + &quot;]&quot;); &#125; while (tempSize &gt; 0) &#123; if (node.equals(head)) &#123; System.out.print(&quot;[&quot; + node.data + &quot;-&gt;&quot;); &#125;else if (node.next == null) &#123; System.out.print(node.data+&quot;]&quot;); &#125;else &#123; System.out.print(node.data+&quot;-&gt;&quot;); &#125; node = node.next; tempSize--; &#125; System.out.println(); &#125;else &#123; System.out.println(&quot;[]&quot;); &#125; &#125;&#125; 测试源码： 123456789101112131415161718public static void main(String[] args) &#123; // TODO Auto-generated method stub SingleLinkedList sLinkedList = new SingleLinkedList(); sLinkedList.addhead(&quot;A&quot;); sLinkedList.addhead(&quot;B&quot;); sLinkedList.addhead(&quot;C&quot;); sLinkedList.addhead(&quot;D&quot;); sLinkedList.display(); sLinkedList.addTail(&quot;O&quot;); sLinkedList.display(); sLinkedList.deleteHead(); sLinkedList.display(); sLinkedList.delete(&quot;B&quot;); sLinkedList.display(); &#125; 测试结果： 1234[D-&gt;C-&gt;B-&gt;A][D-&gt;C-&gt;B-&gt;A-&gt;O][C-&gt;B-&gt;A-&gt;O][C-&gt;A-&gt;O] 这边注意一个地方，addTail()是往链表的末尾添加一个元素，在进行判断current.next == null 后，要先将整体链表的size + 1，不要将size + 1放在循环外进行,才能够使current.next = newTail,否则将无法添加成功，因为容量不够。","tags":[{"name":"算法","slug":"算法","permalink":"http://www.duanmuxu.top/tags/算法/"},{"name":"数据结构","slug":"数据结构","permalink":"http://www.duanmuxu.top/tags/数据结构/"}]},{"title":"StringBuffer 替换字符串中的空格","date":"2019-06-02T04:28:32.269Z","path":"20190602/stringbuffer-replaces-spaces-in-strings.html","text":"题目描述： 1234567将一个字符串中的空格替换成 &quot;%20&quot;。Input:&quot;A B&quot;Output:&quot;A%20B&quot; 解法一：将String Buffer转换为String类型，再进行操作1234567public class Solution &#123; public String replaceSpace(StringBuffer str) &#123; String str1 = str.toString(); str1 = str1.replace(&quot; &quot;,&quot;%20&quot;); return str1; &#125;&#125; 特别简单，不过好像不是出题者的原意 解法二：先填充字符串再进行遍历替换 解题思路：在字符串尾部填充任意字符，使得字符串的长度等于替换之后的长度。因为一个空格要替换成三个字符（%20），因此当遍历到一个空格时，需要在尾部填充两个任意字符。令 P1 指向字符串原来的末尾位置，P2 指向字符串现在的末尾位置。P1 和 P2 从后向前遍历，当 P1 遍历到一个空格时，就需要令 P2 指向的位置依次填充 02%（注意是逆序的），否则就填充上 P1 指向字符的值。从后向前遍是为了在改变 P2 所指向的内容时，不会影响到 P1 遍历原来字符串的内容。 12345678910111213141516171819public String replaceSpace(StringBuffer str) &#123; int P1 = str.length() - 1; for (int i = 0; i &lt;= P1; i++) if (str.charAt(i) == &apos; &apos;) str.append(&quot; &quot;); int P2 = str.length() - 1; while (P1 &gt;= 0 &amp;&amp; P2 &gt; P1) &#123; char c = str.charAt(P1--); if (c == &apos; &apos;) &#123; str.setCharAt(P2--, &apos;0&apos;); str.setCharAt(P2--, &apos;2&apos;); str.setCharAt(P2--, &apos;%&apos;); &#125; else &#123; str.setCharAt(P2--, c); &#125; &#125; return str.toString();&#125;","tags":[{"name":"剑指Offer","slug":"剑指Offer","permalink":"http://www.duanmuxu.top/tags/剑指Offer/"},{"name":"字符串","slug":"字符串","permalink":"http://www.duanmuxu.top/tags/字符串/"},{"name":"算法","slug":"算法","permalink":"http://www.duanmuxu.top/tags/算法/"}]},{"title":"Single Number 找出数组中的单一数字","date":"2019-06-02T04:28:32.252Z","path":"20190602/single-number-find-a-in-the-array.html","text":"题目描述： Given a non-empty array of integers, every element appears twice except for one. Find that single one.给定一个非空的整数数组，除了一个元素外，每个元素都会出现两次。找出那个单一的整数。 最常规的思路就是进行循环，统计出现的数字，只出现一次的就是我们要的答案了 for循环统计数字出现次数123456789101112131415161718192021222324class Solution &#123; public int singleNumber(int[] nums) &#123; int[] result = new int[nums.length]; int count = 0; for (int i = 0;i &lt; nums.length; i++)&#123; for (int j = 0;j &lt;= count;j++)&#123; if (j == count)&#123; result[j] = -1; count++; j = count +1; &#125;else if (nums[i] == nums[j])&#123; result[j]++; count++; j = count + 1; &#125; &#125; &#125; for (int k = 0; k &lt; result.length ;k++)&#123; if (result[k] == -1) return nums[k]; &#125; return 0; &#125;&#125; 新建一个result数组用来存放统计的次数，初始值为-1，进行双重循环，以后每找到一个与nums数组中相同的数字，就在result数组中+1，即值变为0。最后根据result中值为-1（即在nums数组中没找到相同数值的数字）的数字就是我们要找的数字。 这种方法逻辑很顺，但是时间复杂度为O(n^2)，运行时间会消费很多。那么要降低时间复杂度，就得减少一层循环。怎么才能实现呢？既要实现统计次数，又要遍历数组，有应用过Map Reducer方法的同学应该很容易就能想到word count程序好像就是这么一个道理，因此我们可以使用Map进行存值判断。 Map实现123456789101112131415161718class Solution &#123; public int singleNumber(int[] nums) &#123; HashMap&lt;Integer, Integer&gt; result = new HashMap&lt;&gt;(); int resultNum = 0; for(int i = 0; i &lt; nums.length; i++)&#123; int num = nums[i]; if(result.containsKey(num))&#123; result.remove(num); &#125;else&#123; result.put(num, i); &#125; &#125; for (int res : result.keySet()) &#123; resultNum = res; &#125; return resultNum; &#125;&#125; 因为nums数组中的重复数字只有两个，因此判断数字是否已经存在于Map中，若已经存在，则remove该数字，此时Map和nums数组中都已不存在该数字，若Map中不存在该数字，则put该数字。最后Map只剩下单一的数字，即我们想要的结果。 Map中需要插入key-value两个值，但是value的值对我们没有什么帮助，因此可以使用HashSet进一步优化。 HashSet实现1234567891011class Solution &#123; public int singleNumber(int[] nums) &#123; HashSet&lt;Integer&gt; result = new HashSet&lt;&gt;(); for (int num : nums) &#123; if(!result.add(num)) result.remove(num); &#125; Iterator&lt;Integer&gt; it = result.iterator(); return it.next(); &#125;&#125; 判断nums中的数字是否已经存在与HashSet中，若已经存在，则remove，若不存在，则直接add。这步与Map类似，不过只需要插入一个nums数组中的值就够了。 上面都是常规的一些存储方法，可没想到还有一个更加简洁帅气的方法。就是使用异或 ^ 的方法。 XOR异或方法123456789class Solution &#123; public int singleNumber(int[] nums) &#123; int result = 0; for (int num : nums) &#123; result = result ^ num; &#125; return result; &#125;&#125; 什么意思呢，^ 异或满足下面的转化： a b result 0 0 0 0 1 1 1 0 1 1 1 0 所以两个数字进行 ^ 运算时，先将数字转化为二进制，再进行 ^ 操作，当两个数字相同时，则对应的二进制数的位数也都相同，因此运算结果为0。当0与任意数字进行异或运算时，运算结果为该任意数字，因此最终的结果就是nums数组中出现的单一数字。","tags":[{"name":"算法","slug":"算法","permalink":"http://www.duanmuxu.top/tags/算法/"},{"name":"数据结构","slug":"数据结构","permalink":"http://www.duanmuxu.top/tags/数据结构/"}]},{"title":"PAT乙级真题—福尔摩斯的约会","date":"2019-06-02T04:28:32.251Z","path":"20190602/pat-b-level-question-sherlock-holmess-date.html","text":"题目描述 大侦探福尔摩斯接到一张奇怪的字条：“我们约会吧！ 3485djDkxh4hhGE 2984akDfkkkkggEdsb s&amp;hgsfdk d&amp;Hyscvnm”。大侦探很快就明白了，字条上奇怪的乱码实际上就是约会的时间“星期四 14:04”，因为前面两字符串中第1对相同的大写英文字母（大小写有区分）是第4个字母’D’，代表星期四；第2对相同的字符是’E’，那是第5个英文字母，代表一天里的第14个钟头（于是一天的0点到23点由数字0到9、以及大写字母A到N表示）；后面两字符串第1对相同的英文字母’s’出现在第4个位置（从0开始计数）上，代表第4分钟。现给定两对字符串，请帮助福尔摩斯解码得到约会的时间。 输入描述: 输入在4行中分别给出4个非空、不包含空格、且长度不超过60的字符串。 输出描述: 在一行中输出约会的时间，格式为“DAY HH:MM”，其中“DAY”是某星期的3字符缩写，即MON表示星期一，TUE表示星期二，WED表示星期三，THU表示星期四，FRI表示星期五，SAT表示星期六，SUN表示星期日。题目输入保证每个测试存在唯一解。 输入例子: 3485djDkxh4hhGE2984akDfkkkkggEdsbs&amp;hgsfdkd&amp;Hyscvnm 输出例子: THU 14:04 这边注意几点，如果前两个输入中出现连续相同的字母怎么办？如果代表小时的相同字母/数字出现得比代表日期的相同字母要早怎么办？如果后两个输入中有多组相同的字母怎么办？输出中碰到个位数的小时/分钟时前面不带”0”（输出不规范）怎么办？ 这些都不是问题，下面贴出通过的代码，并且有详细注释。可能会显得有些冗长，但是看起来一目了然，毫无难度。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157import java.util.Scanner;public class Holmes &#123; //定义日期 private static char[] day = &#123;&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;, &apos;E&apos;, &apos;F&apos;, &apos;G&apos;&#125;; //定义当天的小时 private static char[] hour =&#123;&apos;0&apos;, &apos;1&apos;, &apos;2&apos;, &apos;3&apos;, &apos;4&apos;, &apos;5&apos;, &apos;6&apos;, &apos;7&apos;, &apos;8&apos;, &apos;9&apos;, &apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;, &apos;E&apos;, &apos;F&apos;, &apos;G&apos;, &apos;H&apos;, &apos;I&apos;, &apos;J&apos;, &apos;K&apos;, &apos;L&apos;, &apos;M&apos;, &apos;N&apos;&#125;; public static void main(String[] args)&#123; //循环读取四个输入 Scanner scanner = new Scanner(System.in); while (scanner.hasNext())&#123; //获取四个字符串 String str1 = scanner.nextLine(); String str2 = scanner.nextLine(); String str3 = scanner.nextLine(); String str4 = scanner.nextLine(); //判断前两个字符串哪一个最短 int daytime = shortest(str1, str2); boolean isDay = true;//判断相同的字母是否是代表“天” String result = &quot;&quot;;//结果字符串 int sum = 0; //前两个字符串中相同字母/数字的个数 for (int i = 0; i &lt; daytime; i++)&#123; if (str1.toCharArray()[i] == str2.toCharArray()[i] &amp;&amp; isInDay(str1.toCharArray()[i]) &amp;&amp; isDay)&#123; result += getDay(str1.toCharArray()[i]); /** * isDay有两个作用： * 一是防止下一次有字母出现时将字母当作成“天”的字母； * 二是供else if 中做判断，防止识别时间在识别周几之前 */ isDay = false; sum++; &#125;else if (str1.toCharArray()[i] == str2.toCharArray()[i] &amp;&amp; isInHour(str1.toCharArray()[i]) &amp;&amp; !isDay )&#123; //输出规范化，防止出现输出为 “THU 2:12”的情况 if (getHour(str1.toCharArray()[i]) &lt; 10)&#123; result += &quot; 0&quot;+ getHour(str1.toCharArray()[i]); sum++; &#125;else &#123; result += &quot; &quot;+ getHour(str1.toCharArray()[i]); sum++; &#125; &#125; //防止已经识别周几和小时之后还有相同又符合判断条件的字母出现 if (sum == 2) break; &#125; //获取str3，str4中最小的字符串长度 int minute = shortest(str3, str4); for (int i = 0; i &lt; minute ; i++)&#123; if (str3.toCharArray()[i] == str4.toCharArray()[i] &amp;&amp; isEnglishChar(str3.toCharArray()[i]))&#123; //输出规范化，与上同 if (i &lt; 10 ) &#123; result += &quot;:0&quot; + i; break; //有相同的字母直接退出for循环 &#125;else &#123; result += &quot;:&quot; + i; break; &#125; &#125; &#125; //输出 System.out.println(result); &#125; &#125; /** * 返回两个字符串长度最小的字符串长度 * @param str1 * @param str2 * @return */ public static int shortest(String str1, String str2)&#123; return str1.length() &lt; str2.length() ? str1.length() : str2.length(); &#125; /*** * 判断输入字符是否存在与day的数组中 * @param character * @return */ public static boolean isInDay(Character character)&#123; for (int i = 0; i &lt; day.length; i++)&#123; if (character == day[i]) return true; &#125; return false; &#125; /** * 判断输入字符是否存在与hour数组中 * @param character * @return */ public static boolean isInHour(Character character)&#123; for (int i = 0; i &lt; hour.length; i++)&#123; if (character == hour[i]) return true; &#125; return false; &#125; /** * 根据输入字符获取星期几的简写 * @param dayChar * @return */ public static String getDay(Character dayChar)&#123; switch (dayChar)&#123; case &apos;A&apos;: return &quot;MON&quot;; case &apos;B&apos;: return &quot;TUE&quot;; case &apos;C&apos;: return &quot;WED&quot;; case &apos;D&apos;: return &quot;THU&quot;; case &apos;E&apos;: return &quot;FRI&quot;; case &apos;F&apos;: return &quot;SAT&quot;; case &apos;G&apos;: return &quot;SUN&quot;; &#125; return &quot;Not Found This Day&quot;; &#125; /** * 根据输入字符获取小时时间 * @param hourChar * @return */ public static int getHour(Character hourChar)&#123; for (int i = 0; i &lt; hour.length; i++)&#123; if (hourChar == hour[i]) return i; &#125; return -1; &#125; /** * 判断输入字符是否是一个英文字母（包含大小写） * @param engChar * @return */ public static boolean isEnglishChar(Character engChar)&#123; if (engChar &gt;= &apos;a&apos; &amp;&amp; engChar &lt;= &apos;z&apos;) return true; else if(engChar &gt;= &apos;A&apos; &amp;&amp; engChar &lt;= &apos;Z&apos;) return true; else return false; &#125;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"http://www.duanmuxu.top/tags/算法/"},{"name":"PAT","slug":"PAT","permalink":"http://www.duanmuxu.top/tags/PAT/"}]},{"title":"往微信图文中插入外链视频的方法（包含几种失败方法）","date":"2019-06-02T04:28:32.249Z","path":"20190602/how-to-insert-an-external-video-into-a-wechat-graphic-including-several-failure-methods.html","text":"几种不同方法最常见方法我们平时转发图文时，往往转发的图文中会带有视频，一般的解决方法就是在浏览器中打开腾讯视频，找到原图文中的原视频，然后进行分享复制链接， 在这里插入图片描述 再把链接复制粘贴到后台视频链接的地方就会有视频显示出来 再点击确定就可以在图文中看见插入的视频了。但是！！前几天在进行转发一篇图文中的视频时我发现了一个新的问题，有些视频点击分享时无法复制视频地址链接，怎么整都不行！所以我先试了以下方法，但都无法实现！为了不让大家走弯路，我先把我用过的行不通的方法列出来。 失败方法一：下载视频上传后台 该视频只有 57 秒，不足 20M（微信公众号后台要求上传的视频大小要小于20M），那我就下载腾讯视频客户端，再下载原视频，然后把视频上传到后台就行了呗，但是问题又出现了，腾讯视频的下载格式是qlv，公众号后台不支持该格式的视频。 不过问题不大，将原视频进行格式转换成 MP4，再上传到后台，还是美滋滋，但是问题又来了，格式工厂无法支持该格式，无法进行转换，那就从网上找吧，可是市面上的格式转换器（对我使用过的而言）转换后的 MP4 格式上传到后台后，公众号后台却无法解码， 因此视频还是无法成功上传，这条路，卒。 利用windows 系统命令行对视频缓存的合成及转换我们每次在浏览器或是客户端进行视频查看时，系统会自动生成缓存保存在电脑中，下次查看视频时就会方便很多，因此我们先找到电脑本地视频缓存区， 腾讯视频将一整段完整的视频进行分段缓存，还都是ts的文件，这个格式第一次见，问题不大，打开 cmd 命令行，使用 copy/b 命令进行分段视频的合成和转换， 合成并转换后的视频文件 视频转换成功，美滋滋。可是问题又来了，点击打开只能在腾讯视频进行播放，其他视频软件出现解码错误（又是解码错误！！） 而且腾讯视频里只有音频，没有视频图像，这条路，卒。 检查网页元素进行视频捕捉和保存知乎上的一个方法，利用浏览器播放视频，检查网页元素进行视频捕捉和保存 如何下载网页上的视频？ - 习惯秋落的回答 - 知乎 有兴趣的可以根据里面详细的介绍试一试 当我开开心心地进行视频保存时，却发现保存的视频格式是ts 文件 在这里插入图片描述 又是ts文件！！！这条路，卒。 手机端UC浏览器进行视频保存平时我们用手机 UC 浏览器进行看视频时，右上角会有一个下载视频的图标，我们可以进行视频下载，一般来说是 MP4 格式，但是前两天我在试验的时候那个图标不见了，我也就没有去深究。 成功方法查找浏览器视频元素既然团中央学校部的图文中可以播放该视频，那这篇图文的信息中肯定有该视频的信息，所以重点来啦，下面都是要记笔记的地方！首先在浏览器中打开我们要转发的图文，我用的是谷歌浏览器，也建议大家使用。 浏览器打开图文 然后打开网页检查元素，一种方法是右击鼠标，选择检查即可，另一种方法是 shift+ctrl+I快捷键进入检查 进入检查页面 点击右边框框中的 element 元素 在这里插入图片描述 键入 ctrl+F 进行元素检索 进行检索 搜索 v.qq.com,因为这个是所有腾讯视频链接中所包含的特定元素 在这里插入图片描述 此时网页自动找到页面中的视频元素（左半边），以及该视频的链接地址（右半边中的黄色部分所在区域），然后呢，我们有了该视频链接的总地址，此时我们复制 src=…后的部分，从 v.qq.com 一直到 false 在这里插入图片描述 然后将我们复制的这段链接再粘贴到后台 在这里插入图片描述 以上就是从原图文找原视频链接地址的方法，十分简便，为什么我之前会试那么多复杂的方法！！ 当然如果腾讯视频可以直接复制视频地址链接，那就不要整这些花里胡哨的。","tags":[{"name":"新媒体","slug":"新媒体","permalink":"http://www.duanmuxu.top/tags/新媒体/"},{"name":"视频","slug":"视频","permalink":"http://www.duanmuxu.top/tags/视频/"}]},{"title":"使用MultipleOutputs方法将mapreduce分组输出","date":"2019-06-02T04:28:32.247Z","path":"20190602/mapreduce-group-output-using-the-multipleoutputs-method.html","text":"MapReduce是我们再进行离线大数据处理的时候经常要使用的计算模型，MapReduce的计算过程被封装的很好，我们只用通过使用Map和Reduce函数，再定义输入输出就能得到我们想要的结果。不过一般Map Reduce的输出只包含一个可视化输出文件（如下图part-r-00000文件），那么我们如果需要将这一个输出文件分为多个输出文件该怎么办呢？ 一个输出 这里就用到了MR框架中的MultipleOutputs函数（MultipleOutputs是2.0之后的新API，是对老版本中MultipleOutputs与MultipleOutputFormat的一个整合）。先来看段完整代码熟悉一下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class dateFormat &#123; static class MyMapper extends Mapper&lt;LongWritable,Text,Text,Text&gt;&#123; @Override protected void map(LongWritable key, Text value,Context context)throws IOException, InterruptedException &#123; SimpleDateFormat simpleDateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd-HH-mm-ss&quot;); String time = simpleDateFormat.format(new Date()); String line = value.toString().trim(); for (int i =0; i&lt; line.length(); i++)&#123; char newChar = line.charAt(i); context.write(new Text(time), new Text(String.valueOf(newChar))); &#125; &#125; &#125; static class MyReducer extends Reducer&lt;Text,Text,Text,Text&gt;&#123; private MultipleOutputs&lt;Text, Text&gt; multipleOutputs; protected void setup(Context context)&#123; multipleOutputs = new MultipleOutputs&lt;Text, Text&gt;(context); &#125; @Override protected void reduce(Text key, Iterable&lt;Text&gt; values,Context context)throws IOException, InterruptedException &#123; for (Text value : values) &#123; multipleOutputs.write((Text) null, value, key.toString()); &#125; &#125; protected void cleanup(Context context) throws IOException, InterruptedException&#123; multipleOutputs.close(); &#125; &#125; public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123; Configuration conf = new Configuration(); Job job = Job.getInstance(conf); job.setJarByClass(dateFormat.class); job.setJobName(&quot;MultipleOutputTest&quot;); job.setMapperClass(MyMapper.class); job.setReducerClass(MyReducer.class); job.setMapOutputKeyClass(Text.class); job.setMapOutputValueClass(Text.class); job.setOutputKeyClass(NullWritable.class); job.setOutputValueClass(Text.class);// MultipleOutputs.addNamedOutput(job, TextOutputFormat.class, NullWritable.class, Text.class); FileInputFormat.setInputPaths(job, new Path(args[0])); Path outPath = new Path(args[1]); FileSystem fs = FileSystem.get(conf); if(fs.exists(outPath)) &#123; fs.delete(outPath, true); &#125; FileOutputFormat.setOutputPath(job, outPath); job.waitForCompletion(true); &#125;&#125; multipleOutputs.write的输出规范如下：multipleOutputs.write((namedOutput,) key, value, baseOutputPath)这里需要注意的一点在是map中的输出值会作为reduce中输出文件的文件命名（map.key-r-00000），即baseOutputPath的值确定了分组输出文件的命名规范。 namedOutput为可选项，为当前输出Job的名称，如果有多于一个multipleOutputs.write时，需指定namedOutput名称，并在Driver里添加 MultipleOutputs.addNamedOutput(job, “namedOutput” , TextOutputFormat.class, NullWritable.class, Text.class);作为作业的入口。 上述的代码段是我根据获取系统时间作为reducer的输入key值，命名时也根据map的执行时间进行命名，输出到同一文件夹之下，具体结果如下图： 分组输出到同一文件下 如果需要将这些文件分别输出到不同的文件夹下，那么只需要将 multipleOutputs.write((Text) null, value, key.toString());中的key.toString()改为key+”/“,即改为multipleOutputs.write((Text) null, value, key+”/“); 即可，输出结果如下： 分组输出到不同文件夹下","tags":[{"name":"大数据","slug":"大数据","permalink":"http://www.duanmuxu.top/tags/大数据/"},{"name":"Hadoop","slug":"Hadoop","permalink":"http://www.duanmuxu.top/tags/Hadoop/"},{"name":"Map Reduce","slug":"Map-Reduce","permalink":"http://www.duanmuxu.top/tags/Map-Reduce/"}]},{"title":"只爱一点点","date":"2019-06-02T04:28:32.246Z","path":"20190602/just-love-a-little-bit.html","text":"不爱那么多，只爱一点点。别人的爱情像海深，我的爱情浅。不爱那么多，只爱一点点。别人的爱情像天长，我的爱情短。不爱那么多，只爱一点点。别人眉来又眼去，我只偷看你一眼。 在这里插入图片描述","tags":[{"name":"现代诗","slug":"现代诗","permalink":"http://www.duanmuxu.top/tags/现代诗/"}]},{"title":"Java实现从尾到头打印链表（ListNode）每个节点的值","date":"2019-06-02T04:28:32.243Z","path":"20190602/java-implementation-prints-the-value-of-each-node-from-end-to-linked-list-listnode.html","text":"进行做题之前，先来看看什么是ListNode。 ListNode是由自己定义的Java中的链表对象(其实也可以理解成C语言中的链表)。也就是在Java类库中没有这个类，需要自己定义。定义如下： 123456789public class ListNode&#123; int val; ListNode next; public ListNode(int x)&#123; val=x; &#125;&#125; val表示当前ListNode的值，next指向下一个ListNode。在进行ListNode初始化时必须传值，如下面main函数中进行初始化： 123456public static void main(String[] args) &#123; ListNode listNode = new ListNode(1); listNode.next = new ListNode(3); listNode.next.next = new ListNode(4); listNode.next.next.next = new ListNode(1); &#125; 此时生成链表：1-&gt;3-&gt;4-&gt;1 题目描述： 1输入一个链表，按链表值从尾到头的顺序返回一个ArrayList。 方法一：利用栈的思想一个链表从头到尾输入，要求输出的是从尾到头。符合栈先进后出的思想，因此可以用下面方法实现： 123456789101112131415 public ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode) &#123;Stack&lt;Integer&gt; stack = new Stack&lt;Integer&gt;();while (listNode != null) &#123; stack.push(listNode.val); listNode = listNode.next;&#125;ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;();while (!stack.isEmpty()) &#123; arrayList.add(stack.pop());&#125; return arrayList; &#125; 方法二：递归123456789public ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode) &#123; ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;(); if (listNode != null) &#123; arrayList.addAll(printListFromTailToHead(listNode.next)); arrayList.add(listNode.val); &#125; return arrayList; &#125; 顺便说一下addAll()和all()的区别： add（）是将传入的的参数作为当前 List 中d的一个项目（Item）来存储，即使你传入一个 list 也只会另当前的List集合增加 1 个元素。addAll（）是传入一个List，将此前List集合中的所有元素加入到当前的 List 中，当前 List 集合会增加的元素个数是传入的 List 的大小。 方法三：头插法利用链表头插法为逆序的特点： 123456789101112131415161718public ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode) &#123; ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;&gt;(); ListNode head = new ListNode(-1); while (listNode != null) &#123; ListNode q = listNode.next; listNode.next = head.next; head.next = listNode; listNode = q; &#125; head = head.next; while (head != null) &#123; arrayList.add(head.val); head = head.next; &#125; return arrayList;&#125; 方法四：链表翻转 利用函数： 1234567891011public ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); while(listNode != null)&#123; list.add(listNode.val); listNode = listNode.next; &#125; Collections.reverse(list);//使用Collections的reverse方法，直接将list反转 return list;&#125; 强行进行逆序 123456789101112131415161718public ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode) &#123; ArrayList&lt;Integer&gt; arr = new ArrayList&lt;Integer&gt;(); if(listNode == null)&#123; return arr; &#125; while(listNode.next != null)&#123; arr.add(listNode.val); listNode = listNode.next; &#125; arr.add(listNode.val); int temp = 0; for(int inx=0, end=arr.size()-1; inx&lt;end; inx++, end--)&#123; temp = arr.get(inx); arr.set(inx, arr.get(end)); arr.set(end, temp); &#125; return arr;&#125;","tags":[{"name":"剑指Offer","slug":"剑指Offer","permalink":"http://www.duanmuxu.top/tags/剑指Offer/"},{"name":"算法","slug":"算法","permalink":"http://www.duanmuxu.top/tags/算法/"},{"name":"数据结构","slug":"数据结构","permalink":"http://www.duanmuxu.top/tags/数据结构/"}]},{"title":"查找二叉树的下一个节点（中序遍历）","date":"2019-06-02T04:28:32.229Z","path":"20190602/find-the-next-node-of-binary-tree-middle-order-traversal.html","text":"首先我们先了解一下二叉树的三种遍历方法： 前序遍历：从根节点开始，根在前，从左往右，一棵树的根永远在左子树前面，左子树又永远在右子树前面； 中序遍历：从最左节点开始，根在中，从左往右，一棵树的左子树永远在根前面，根永远在右子树前面； 后序遍历：也是从最左节点开始，根在后，从左往右，一棵树的左子树永远在右子树前面，右子树永远在根前面。 比如下面一张图 image 前序遍历为：ABDGHECKFIJ 中序遍历为：GDHBEAKCIJF 后序遍历为：GHDEBKJIFCA 了解了二叉树的大致遍历方式，我们来看下题目： 给定一个二叉树和其中的一个结点，请找出中序遍历顺序的下一个结点并且返回。注意，树中的结点不仅包含左右子结点，同时包含指向父结点的指针。 通过中序遍历我们可以知道一个节点的下一个节点有两种情况： 如果一个节点的右子树不为空，那么该节点的下一个节点是右子树的最左节点，比如上图中C的后一个节点是I； 如果一个节点的右子树为空，那么向上找第一个左链接指向的树包含该节点的父节点。比如上图H的下一个节点是B。 接下来看代码实现： 12345678910111213// 定义一棵树public class TreeLinkNode &#123; int val; TreeLinkNode left = null; TreeLinkNode right = null; TreeLinkNode next = null; TreeLinkNode(int val) &#123; this.val = val; &#125;&#125; 12345678910111213141516171819202122public class Solution &#123; public TreeLinkNode GetNext(TreeLinkNode pNode) &#123; //判断该节点是否存在右子节点 if(pNode.right != null)&#123; //如果有右子树，则找右子树的最左节点 TreeLinkNode rightNode = pNode.right; while(rightNode.left != null) rightNode = rightNode.left; return rightNode; &#125;else&#123; //没右子树，则找第一个当前节点是父节点左孩子的节点 while(pNode.next != null)&#123; TreeLinkNode parentNode = pNode.next; if(parentNode.left == pNode) return parentNode; pNode = pNode.next; &#125; &#125; return null; &#125;&#125;","tags":[{"name":"剑指Offer","slug":"剑指Offer","permalink":"http://www.duanmuxu.top/tags/剑指Offer/"},{"name":"算法","slug":"算法","permalink":"http://www.duanmuxu.top/tags/算法/"},{"name":"数据结构","slug":"数据结构","permalink":"http://www.duanmuxu.top/tags/数据结构/"}]},{"title":"剑指Offer中关于斐波那契数列的分析和运用","date":"2019-06-02T04:28:32.227Z","path":"20190602/analysis-and-application-of-the-fibonacci-sequence-in-sword.html","text":"我们先来看一下什么是斐波那契数列，这个应该在大一高数时大家都学过。 斐波那契数列（Fibonacci sequence），又称黄金分割数列、因数学家列昂纳多·斐波那契（Leonardoda Fibonacci）以兔子繁殖为例子而引入，故又称为“兔子数列”，指的是这样一个数列：1、1、2、3、5、8、13、21、34、……在数学上，斐波纳契数列以如下被以递推的方法定义：F(1)=1，F(2)=1, F(n)=F(n-1)+F(n-2)（n&gt;=3，n∈N*）——《百度百科》 具体函数表达参考下面这张图。 img 那么我们该如何求解与斐波那契数列相关的问题呢？先看一下题目描述： 大家都知道斐波那契数列，现在要求输入一个整数n，请你输出斐波那契数列的第n项（从0开始，第0项为0）。 具体可以用以下几种方法求解： 使用递归递归能将一个问题划分成多个子问题进行求解。求F(n)时会转化成求F(n-1)、F(n-2),以此类推，最后转化成几个F(0)、F(1)相加的结果。实现如下： 1234567891011public class Solution &#123; public int Fibonacci(int n) &#123; int result = 0; if (n &lt;= 1)&#123; return n; &#125;else&#123; result = Fibonacci(n - 1) + Fibonacci(n - 2); &#125; return result; &#125;&#125; 运行时间与占用内存如下： img 可是使用递归会有一个问题，会重复计算一些子问题。比如计算F(5)需要计算F(4)和F(3)，计算F(4)需要计算F(3)和F(2)，可以看到F(3)被重复计算了。造成了资源浪费。 所以我们换个思路。 动态规划递归是将一个问题划分成多个子问题进行求解。动态规划相当于是个相反的过程，将子问题的解存储起来，用来解决大问题，比如已知F(0)、F(1)，进行求F(2)，再进一步求F(3)，以此类推，直至求到F(n)。这样子就不会有重复求解子问题的烦恼产生。实现如下： 123456789101112131415public class Solution &#123; public int Fibonacci(int n) &#123; if (n &lt;= 1)&#123; return n; &#125; int[] fib = new int[n+1]; fib[0] = 0; fib[1] = 1; for(int i = 2;i &lt; n + 1; i++)&#123; fib[i] = fib[i - 1] + fib[i - 2]; &#125; return fib[n]; &#125;&#125; 运行时间与占用内存如下： img 这么做比递归好很多，但是考虑到第i项只与第i-1和第i-2项有关，因此只需要存储前两项的值就能求解第i项，从而将空间复杂度由O(N)降低为O(1)。所以我们可以进一步优化。 动态规划的进一步优化使用两个值存储i-1和i-2，避免使用数组，浪费更多的空间。实现如下： 12345678910111213141516public class Solution &#123; public int Fibonacci(int n) &#123; if (n &lt;= 1)&#123; return n; &#125; int preOne = 1; //存储i-1 int preTwo = 0; //存储i-2 int result = 0; for(int i = 2;i &lt; n + 1; i++)&#123; result = preOne + preTwo; preTwo = preOne; preOne = result; &#125; return result; &#125;&#125; 运行时间与占用内存如下： img 接下来我们来看看剑指Offer中其他关于斐波那契数列的运用的题目： 题目一：跳台阶 一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法（先后次序不同算不同的结果）。 简单分析一下，就可以知道还是上面斐波那契数列的变化，青蛙跳1级台阶有1种跳法，2级台阶有2种跳法，3级台阶时可以从1级台阶跳上来也可以从2级台阶跳上来，即等于1级台阶的跳法加2级台阶的跳法因此n级台阶共有n-2级台阶跳法数+n-1级台阶跳法数。 实现如下： 12345678910111213141516public class Solution &#123; public int JumpFloor(int target) &#123; if(target &lt;= 2) return target; int preOne = 2; int preTwo = 1; int result = 0; for(int i = 3;i &lt; target+1 ;i++)&#123; result = preOne + preTwo; preTwo = preOne; preOne = result; &#125; return result; &#125;&#125; 题目二：变态跳台阶 一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法 上一题的升级版，跳n级台阶时可以允许跳1~n任意阶级的台阶。先来分析一下 跳n级台阶，那么第一步有n种跳法：跳1级、跳2级、到跳n级 跳1级，剩下n-1级，则剩下跳法是F(n-1)； 跳2级，剩下n-2级，则剩下跳法是F(n-2)； 所以F(n)=F(n-1)+F(n-2)+…+F(1)+1，最后的+1是因为直接跳n级台阶只有一种方法； 因为F(n-1)=F(n-2)+F(n-3)+…+F(1)+1; 以此类推，得F(n)=2*F(n-1)。 分析后变得比上面一提还要简单。实现如下： 123456789101112131415public class Solution &#123; public int JumpFloorII(int target) &#123; if(target &lt;= 2)&#123; return target; &#125; int preNum = 2; int result = 0; for(int i = 3;i &lt; target + 1;i++)&#123; result = 2 * preNum; preNum = result; &#125; return result; &#125;&#125; 题目三：矩阵覆盖 我们可以用2 * 1的小矩形横着或者竖着去覆盖更大的矩形。请问用n个2 * 1的小矩形无重叠地覆盖一个2 * n的大矩形，总共有多少种方法？ 再来分析一下 首先从n=1开始，小矩阵只能竖着放，只有一种方法； n=2时，大矩阵为2 * 2，小矩阵既可以竖着放也可以横着放，有两种方法； 当n越来越大时，如果第一步选择竖着放，如下图： 第一步：竖着放 那么大矩阵的规模缩小成2 * (n-1)； 如果第一步选择竖着放，那么第二排也只能横着放，如下图： 第一步：横着放 那么大矩阵的规模缩小成2 * (n-2)； 因此，题目又转化成了与题目一一样的斐波那契数列了。实现如下： 12345678910111213141516public class Solution &#123; public int RectCover(int target) &#123; if(target &lt;= 2) return target; int preOne = 2; int preTwo = 1; int result = 0; for(int i = 3;i &lt; target+1 ;i++)&#123; result = preOne + preTwo; preTwo = preOne; preOne = result; &#125; return result; &#125;&#125; 以上就是关于斐波那契数列的含义和使用方式，题目一二三都是剑指Offer中的真题，示例中关于运行时间和占用内存是根据牛客网的测试用例得来的。","tags":[{"name":"剑指Offer","slug":"剑指Offer","permalink":"http://www.duanmuxu.top/tags/剑指Offer/"},{"name":"算法","slug":"算法","permalink":"http://www.duanmuxu.top/tags/算法/"},{"name":"数据结构","slug":"数据结构","permalink":"http://www.duanmuxu.top/tags/数据结构/"}]},{"title":"关于Storm（一）Storm简介","date":"2019-06-02T04:28:32.198Z","path":"20190602/about-storm-1.html","text":"什么是StormApache Storm是Apache与基金会的开源的分布式实时计算系统。与Hadoop的批处理相类似，Storm可以对大量的数据流进行可靠的实时处理，这一过程也称为“流式处理”，是分布式大数据处理的一个重要方向。Storm支持多种类型的应用，包括：实时分析、在线机器学习、连续计算、分布式 RPC（ DRPC）、ETL等。Strom的一个重要特点就是“快速”的数据处理，有benchmark示显示Storm级能够达到单个节点每秒百万级tuple处理（tuple是Storm的最小数据单元）的速度。快速的数据是处理、优秀的可扩展性与容错性、便捷的可操作性与维护性、活跃的社区技术支持，这就是 Storm 。 Hadoop与Storm的比较相似之处 Hadoop Storm 系统角色 JobTracker Nimbus TaskTracker Supervisor Child Worker 应用名称 Job Topology 组件接口 Mapper/Reducer Spout/Bolt - Nimbus：Nimbus在Storm中用于资源分配和作业调度，类比Hadoop中的Job Tracker - Supervisor：Supervisor在Storm中用于接收Nimbus分配的任务，并且启动和停止用于完成这些任务对的Worker进程。Supervisor类比Hadoop中的TaskTracker - Worker：运行Storm中具体组件逻辑的进程。这里的组件指的是Spout或者Bolt，对比Hadoop.x的Child进程。 - Topology：Topology是Storm中运行的一个任务，类比Hadoop.x中的一个作业（Job） - Spout：在一个Topology中产生源数据流的组件 - Bolt：在一个Topology中接收数据，并进行逻辑处理的组件，称为Transformation 不同之处 Hadoop Storm 数据来源 Hadoop处理的是HDFS上TB级别的数据（历史数据） Storm处理的是实时新增的某一笔数据（实时数据） 处理过程 Hadoop是分Map阶段和Reduce阶段 Storm是由用户定义处理流程，流程中可以包含多个步骤，每个步骤可以是数据源（Spout）或处理逻辑（Bolt） 是否结束 Hadoop最后是要结束的 Storm没有结束状态，到最后一步时，就停在那，直到有新数据进入时再从头开始 处理速度 Hadoop是以处理HDFS上大量数据为目的的，处理速度慢 Storm是只要处理新增的某一笔数据即可，可以做到很快 适用场景 Hadoop是在要处理批量数据时用的，不讲究时效性 Storm是要处理某一新增数据时使用的，讲究时效性 ps：在Hadoop集群上运行MapReduce jobs，在Storm集群上运行topologies。jobs和topologies有很大的不同。一个关键区别是：一个Map Reduce jobs最终可以完成，而topologies处理过程将永远执行（除非Kill it） Storm组件 image Storm集群中包含两类节点：主控节点（Master Node）和工作节点（Work Node） 主控节点上运行着Nimbus，负责在Storm集群内分发代码，分配任务给工作机器，并且负责监控集群运行状态 工作节点上运行着Supervisor，负责监听从Nimbus分配给它执行的任务，据此启动或停止任务的工作进程。 每一个工作进程执行一个Topology的子集；一个运行中的Topology由分布在不同工作节点上的多个工作进程组成。 Nimbus 和和 Supervisor节点之间所有的协调工作是通过Zookeeper集群来实现的。此外，Nimbus 和Supervisor进程都是快速失败（fail-fast) 和 无状态（stateless） 的；Storm集群所有的状态要么在Zookeeper集群中，要么存储在本地磁盘上。这意味着我们可以用kill-9来杀死Nimbus和Supervisor进程，它们在重启后可以继续工作。这个设计使得Storm集群拥有极强的稳定性。","tags":[{"name":"Storm","slug":"Storm","permalink":"http://www.duanmuxu.top/tags/Storm/"}]}]